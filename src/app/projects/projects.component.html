<!-- Projects Container -->
<div class="container">
    <div class="table">
         <!-- START Multimodal Project -->
            <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
                    <div class="col-md-4 .portrait">
                        <img src="assets/images/general/abstract_bg2.jpg">
                    </div>
                    <div class="col-md-8">
                        <h2>Multi-Modal Gesture Recognition: Gesture + Speech</h2>
                        <h4><b>In Progress</b></h4>
                        <h6>OpenHID Lab, HPDRC, among others</h6>
                        <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                        <p style = "text-align: justify">This project is currently being researched to developed gesture+speech gesture recognition.</p>
                        
                    </div>
                </div>
               <!-- END Multimodal Project -->
               <br>

        <!-- START Gesture User Preference Project -->
        <div class="row" style=" padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg4.jpg">
                </div>
                <div class="col-md-8">
                    <h2>Gesture User Preference and Elicitation</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">This project seeks to advance the understanding of user preferences and elicitation for gesture interaction (including multi-modality that includes gestures).</p>
                    
                </div>
            </div>
           <!-- END Gesture User Preference Project -->
           <br>

         <!-- START Improving Computer Science Education Project -->
         <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg2.jpg">
                </div>
                <div class="col-md-8">
                    <h2>Improving Computer Science Education using Virtual and Augmented Reality Tools</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">This projects is developing surveys to understand freshmen and sophomore non-cs students understanding of Computer Sciences and seeks to motivate them using virtual reality and augmented reality tools.</p>
                    
                </div>
            </div>
           <!-- END Improving Computer Science Education Project -->
           <br>

         <!-- START Architecture Studio 101 Project -->
         <div class="row" style=" padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg4.jpg">
                </div>
                <div class="col-md-8">
                    <h2>Architecture Studio 101: The Cube. Improving Architecture education with Virtual Reality Tools</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">This projects is developing the typical "cube" process created in most studios 101 around the US. We are trying to understand the differences affordances and how this improves architecture education.</p>
                    
                </div>
            </div>
           <!-- END Architecture Studio 101 Project -->
           <br>

         <!-- START Improving Senior Citizen living spaces Project -->
         <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg2.jpg">
                </div>
                <div class="col-md-8">
                    <h2>Improving Senior Citizen living spaces in Miami-Dade County (Coconut Grove, FL)</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">This projects uses Virtual and Augmented reality to improve spaces around communities where senior citizens share spaces with much younger crowds and how we can improve their daily activities.</p>
                    
                </div>
            </div>
           <!-- END Improving Senior Citizen living spaces Project -->
           <br> 
        
        <!-- START Understanding User's uncertainty with Augmented Reality Project -->
        <div class="row" style=" padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg4.jpg">
                </div>
                <div class="col-md-8">
                    <h2>Understanding User's uncertainty with Augmented Reality</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">TBA</p>
                    
                </div>
            </div>
           <!-- END Understanding User's uncertainty with Augmented Reality Project -->
           <br>

        <!-- START American Sign Language Gesture Recognition Project -->
        <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
                <div class="col-md-4 .portrait">
                    <img src="assets/images/general/abstract_bg2.jpg">
                </div>
                <div class="col-md-8">
                    <h2>American Sign Language Gesture Recognition</h2>
                    <h4><b>In Progress</b></h4>
                    <h6>OpenHID Lab, HPDRC, among others</h6>
                    <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                    <p style = "text-align: justify">TBA</p>
                    
                </div>
            </div>
           <!-- END American Sign Language Gesture Recognition Project -->
           <br> 

        <!-- START CirGR Project -->
        <div class="row" style="padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/circgr-preview.png">
            </div>
            <div class="col-md-8">
                <h2>CircGR: Multi-touch Gesture Recognition</h2>
                <h4><b>Complete</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</b></h6> -->
                <p style = "text-align: justify">CircGR is a multi-touch non-symbolic gesture recognition algorithm, which utilizes circular statistic measures to implement linearithmic (O(n log n)) template-based matching. CircGR provides a solution to gesture designers, which allows for building complex multi-touch gestures with high- confidence accuracy. We demonstrated the algorithm and described a user study with 60 subjects and over 12,000 gestures collected for an original gesture set of 36. The accuracy is over 99% with the Matthews correlation coefficient of 0.95. In addition, early gesture detection was successful in CircGR as well.</p>
                <a class="btn btn-success" style="padding:6px" href="http://circgr.com">Website</a>
            </div>
        </div>
        <!-- END CirGR Project -->
        <br>
        <!-- START CodeVR Project -->
        <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/codevr-preview.png">
            </div>
            <div class="col-md-8">
                <h2>CodeVR</h2>
                <h4><b>In Progress</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>Ortega, Rishe, Galvan, Borges</b></h6> -->
                <p style = "text-align: justify">This project seeks to improve Computer Science education using virtual reality for computer science students.</p>
                <a class="btn btn-success" style="padding:6px" href="https://github.com/openhid/code-vr">Github</a>            
            </div>
        </div>
        <!-- END CodeVR Project -->
        <!-- <br> -->
        <!-- START Multimodal Project -->
        <!-- <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/abstract_bg2.jpg">
            </div>
            <div class="col-md-8">
                <h2>Multimodal Gesture Recognition for Multi-touch and Pen</h2>
                <h4><b>In Progress</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <h6><b>Ortega, Rishe, Balcazar, Thomas, Galvan</b></h6>
                <p style = "text-align: justify">This project seeks to find minimal features for gesture recognition in a multimodal environment using multitouch and pen, while keeping the complexity of of the implementation aligned with the $ (dollar) family algorithms.</p>
                 <a class="btn btn-success" style="padding:6px" href="https://github.com/openhid/code-vr">Github</a>             
            </div>
        </div> -->
        <!-- END Multimodal Project -->
       <!-- <br> -->
        <!-- START VR Programming Project -->
        <!-- <div class="row" style="padding:20px">
            <div class="col-md-4 .portrait">
                <img width="300" height="200" src="assets/images/general/abstract_bg4.jpg">
            </div>
            <div class="col-md-8">
                <h2>VR Programming Application</h2>
                <h4><b>In Progress</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <h6><b>Ortega, Rishe, Galvan</b></h6>
                <p style = "text-align: justify">A VR programming application for increasing the number of women and minorities in computer science. </p>
                <a class="btn btn-success" style="padding:6px" href="https://github.com/openhid/code-vr">Github</a>             
        </div> -->
        <!-- END VR Programming Project -->
        <!-- <br> -->
        <!-- START Procedural Skybox Project -->
        <div class="row" style=" padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/space.png" style="height:200px">
            </div>
            <div class="col-md-8">
                <h2>Procedural Skybox Generation</h2>
                <h4><b>Completed</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>Ortega, Rishe, Galvan</b></h6> -->
                <p style = "text-align: justify">An algorithm for efficiently generating a physically correct space skybox for use in real time rendering.</p>
                <a class="btn btn-success" style="padding:6px" href="http://ieeexplore.ieee.org/abstract/document/7893331/">IEEE Xplore</a>
                <a class="btn btn-success" style="padding:6px" href="http://openhid.com/assets/papers/gesture_elicitation_for_3d_travel_via_multi-touch_and_mid-air_systems_for_procedurally_generated_pseudo-universe.pdf">PDF</a>
            </div>
        </div>
        <!-- END Procedural Skybox Project -->
        <br>
        <!-- START Gesture Elicitation Project -->
        <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/3d-elicitation.png" style="height:200px">
            </div>
            <div class="col-md-8">
                <h2>Gesture Elicitation for 3D</h2>
                <h4><b>Completed</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>(Hidden for Now)</b></h6> -->
                <p style = "text-align: justify">This atempts to elicit gestures from multitouch/vision based cameras to study different aspects of travel and wayfinding.</p>
                <a class="btn btn-success" style="padding:6px" href="http://ieeexplore.ieee.org/abstract/document/7893331/">IEEE Xplore</a>
                <a class="btn btn-success" style="padding:6px" href="http://nuilab.org/assets/papers/gesture_elicitation_for_3d_travel_via_multi-touch_and_mid-air_systems_for_procedurally_generated_pseudo-universe.pdf">PDF</a>
            </div>
        </div>
        <!-- END Gesture Elicitation Project -->
        <br>
        <!-- START 3D Navigation Project -->
        <div class="row" style="padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/3d-navigation.png" style="height:200px">
            </div>
            <div class="col-md-8">
                <h2>3D Navigation (Using Multitouch Desktop Displays)</h2>
                <h4><b>Completed</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>Ortega, Barreto, Rishe, Jennifer Fernadez, Christian Martinez, Jules Calella</b></h6> -->
                <p style = "text-align: justify">This atempts to elicit gestures from multitouch/vision based cameras to study different aspects of travel and wayfinding.</p>
                <a class="btn btn-success" style="padding:6px" href="http://nuilab.org/assets/papers/procedural_celestial_rendering_for_3d_navigation.pdf">PDF</a>
            </div>
        </div>
        <!-- END 3D Navigation Project -->
        <br>
        <!-- START Smart Learning Desk Project -->
        <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/smart-desk.png" style="height:200px"> 
            </div>
            <div class="col-md-8">
                <h2>Smart Learning Desk</h2>
                <h4><b>Completed</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <!-- <h6><b>Ortega, Rishe, Emmanuel Norde, Bryan Rodriguez, Fernando Garcia, Juan Araguren, Galvan, Thomas, Balcazar</b></h6> -->
                <p style = "text-align: justify">The Smart Learning Desk is currently being developed to integrate vision and touch targeted for the advancement of K-12 and college education.</p>
                <a class="btn btn-success" style="padding:6px" href="https://sites.google.com/site/vrkelvar/vr2016">Webpage</a>
                <a class="btn btn-success" style="padding:6px" href="assets/papers/Ortega-smartdesk.pdf">Paper</a>
            </div>
        </div>
        <!-- END Smart Learning Desk Project -->
        <!-- <br> -->
        <!-- TAMGeF Project -->
        <!-- <div class="row" style="background-color: rgba(235,235,235, 0.9); padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/abstract_bg2.jpg">
            </div>
            <div class="col-md-8">
                <h2>TAMGeF: Touch, midAir, and Motion Gesture Framework</h2>
                <h4><b>In Progress</b></h4>
                <h6>OpenHID Lab, HPDRC, among others</h6>
                <h6><b>Ortega, Rishe, Thomas, Balcazar, Galvan</b></h6>
                <p style = "text-align: justify">TAMGeF is a modern, parallel, template-based C++ API for multi-touch (and pen), mid-air (vision-based devices), and motion (e.g., gyroscope) devices with the purpose of recognizing multiple gestures.</p>
                <a class="btn btn-success" style="padding:6px" href="https://www.youtube.com/watch?v=PbSF8dhGgpA"><i class="fa fa-youtube"></i>YouTube</a>
                <a class="btn btn-success" style="padding:6px" href="https://dl.acm.org/citation.cfm?id=2794355">ACM</a>
                <a class="btn btn-success" style="padding:6px" href="http://openhid.com/assets/papers/tamgef-_touch-midair-motion_framework_for_spatial_input.pdf">PDF</a>
            </div>
        </div> -->
        <!-- END TAMGeF Project -->
        <!-- <br> -->
        <!-- TAMGeF Project -->
        <div class="row" style="padding:20px">
            <div class="col-md-4 .portrait">
                <img src="assets/images/general/spider-sensor.png" style="height: 200px; width: 500px">
            </div>
            <div class="col-md-8">
                <h2>Spider Sensor</h2>
                <h4><b>Completed</b></h4>
                <h6>OpenHID Lab, HPDRC, Calella, among others</h6>
                <!-- <h6><b>Ortega, Barreto, Rishe</b></h6> -->
                <p style = "text-align: justify">The project covers the design of new hardware for motion sensing and the development of gesture algorithms for this type of sensor. </p>
                <a class="btn btn-success" style="padding:6px" href="http://ieeexplore.ieee.org/abstract/document/7808524/">IEEE Xplore</a>
                <a class="btn btn-success" style="padding:6px" href="http://openhid.com/assets/papers/handmagic-_towards_user_interaction_with_inertial_measuring_units.pdf">ABC</a>
            </div>
        </div>
        <!-- END TAMGeF Project -->
    </div>
</div>

