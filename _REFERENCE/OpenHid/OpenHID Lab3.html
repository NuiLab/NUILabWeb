<!DOCTYPE html>
<!-- saved from url=(0028)http://openhid.com/projects/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>OpenHID Lab</title>
    <!-- Search Engines-->
    <meta name="author" content="Florida International University - OpenHID Lab">
    <meta name="description" content="The OpenHID Lab of Florida International University, dedicated to the research and development of 3D User Interfaces, Virtual Environments, among other topics.">
    <meta name="keywords" content="florida, international, miami, university, research, lab, graphics, human interface device, IO, Computer Science (CS), FIU SCIS, FIU CS, computer graphics, mathematics, rendering, demo, 3D, realtime, shader, raytracing, glsl">
    <!-- Twitter-->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@OpenHID">
    <meta name="twitter:title" content="OpenHID Lab @ FIU CIS">
    <meta name="twitter:description" content="The OpenHID Lab of Florida International University, dedicated to the research and development of 3D User Interfaces, Virtual Environments, among other topics.">
    <meta name="twitter:image" content="http://openhid.com/assets/brand/cover.jpg">
    <!-- Facebook-->
    <meta property="og:title" content="OpenHID Lab @ FIU CIS">
    <meta property="og:url" content="htt://OpenHID.com">
    <meta property="og:site_name" content="OpenHID Lab">
    <meta property="og:image" content="http://openhid.com/assets/brand/cover.jpg" itemprop="thumbnailUrl">
    <!-- Icons/Mobile-->
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <link rel="apple-touch-icon" href="http://openhid.com/assets/brand/icon-57.png">
    <link rel="apple-touch-icon" sizes="72x72" href="http://openhid.com/assets/brand/icon-72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="http://openhid.com/assets/brand/icon-114.png">
    <link rel="shortcut icon" href="http://openhid.com/assets/brand/icon.ico">
    <!-- App Start-->
    <link rel="stylesheet" href="./OpenHID Lab3_files/main.css">
  </head>
  <body cz-shortcut-listen="true">
    <nav class="linkbar fade-down">
      <ul>
        <li><a href="http://openhid.com/">Home</a></li>
        <li><a href="http://openhid.com/about">About Us</a></li>
        <li><a href="http://openhid.com/projects">Projects</a></li>
        <li><a href="http://openhid.com/contact">Contact</a></li>
        <li><a href="http://openhid.com/publications">Publications</a></li>
        <li><a href="http://3dinputbook.com/">Books</a></li>
        <!--lia(href='/events') Events
        -->
        <li><a href="http://openhid.com/resources">Resources</a></li>
        <li><a href="https://users.cs.fiu.edu/~fortega/">Teaching</a></li>
        <li><a href="http://openhidlab.tumblr.com/">Blog</a></li>
      </ul>
    </nav>
    <div style="background-color: rgba(46, 146, 117, 0.55)" class="fullscreen-video"></div>
    <div class="hero">
      <article>
        <h1>CircGR: Multi-touch Gesture Recognition</h1>
        <h3>Complete</h3>
        <h4>OpenHID Lab, HPDRC, among others</h4>
        <h4>Balcazar, R., Ortega, F., Tarre, K., Barreto, A., Weiss, M., Rishe, N.</h4>
        <p>CircGR is a multi-touch non-symbolic gesture recognition algorithm, which utilizes circular statistic measures to implement linearithmic (O(n log n)) template-based matching. CircGR provides a solution to gesture designers, which allows for building complex multi-touch gestures with high- confidence accuracy. We demonstrated the algorithm and described a user study with 60 subjects and over 12,000 gestures collected for an original gesture set of 36. The accuracy is over 99% with the Matthews correlation coefficient of 0.95. In addition, early gesture detection was successful in CircGR as well.</p><a style="padding:16px" href="http://circgr.com/">website</a>
      </article>
    </div>
  
  <section style="background-color: rgba(255,255,255, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/codevr-preview.png">
    <article style="padding: 16px">
      <h2>CodeVR</h2>
      <h3>In Progress</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4> Ortega, Rishe, Galvan, Borges</h4>
      <p>This project seeks to improve computer science education using virtual reality for computer science students.</p><a style="padding:16px" href="https://github.com/openhid/code-vr">github</a>
    </article>
  </section>
  <section style="background-color: rgba(235,235,235, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>Multimodal Gesture Recognition for Multi-touch and Pen</h2>
      <h3>In Progress</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4> Ortega, Rishe, Balcazar, Thomas, Galvan</h4>
      <p>This project seeks to find minimal features for gesture recognition in a multimodal environment using multitouch and pen, while keeping the complexity of of the implementation aligned with the $ (dollar) family algorithms.</p>
    </article>
  </section>
  <section style="background-color: rgba(255,255,255, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>VR Programming Application</h2>
      <h3>In Progress</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4>Ortega, Rishe, Galvan</h4>
      <p>A VR programming application for increasing the number of women and minorities in computer science. </p>
    </article>
  </section>
  <section style="background-color: rgba(235,235,235, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>Procedural Skybox Generation</h2>
      <h3>Completed</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4>Ortega, Rishe, Galvan</h4>
      <p>An algorithm for efficiently generating a physically correct space skybox for use in real time rendering.</p><a style="padding:16px" href="http://ieeexplore.ieee.org/abstract/document/7893331/">IEEE Xplore</a><a style="padding:16px" href="http://openhid.com/assets/papers/gesture_elicitation_for_3d_travel_via_multi-touch_and_mid-air_systems_for_procedurally_generated_pseudo-universe.pdf">pdf</a>
    </article>
  </section>
  <section style="background-color: rgba(255,255,255, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>Gesture Elicitation for 3D</h2>
      <h3>Completed</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4>(Hidden for Now)</h4>
      <p>This atempts to elicit gestures from multitouch/vision based cameras to study different aspects of travel and wayfinding.</p><a style="padding:16px" href="http://ieeexplore.ieee.org/abstract/document/7893331/">IEEE Xplore</a><a style="padding:16px" href="http://openhid.com/assets/papers/gesture_elicitation_for_3d_travel_via_multi-touch_and_mid-air_systems_for_procedurally_generated_pseudo-universe.pdf">pdf</a>
    </article>
  </section>
  <section style="background-color: rgba(235,235,235, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>3D Navigation (Using Multitouch Desktop Displays)</h2>
      <h3>Completed</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4>Ortega, Barreto, Rishe, Jennifer Fernadez, Christian Martinez, Jules Calella</h4>
      <p>An earlier iteration of the gesture elicitation experiment, developed in Ogre, to test navigation with multitouch.</p>
    </article>
  </section>
  <section style="background-color: rgba(255,255,255, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>Smart Learning Desk</h2>
      <h3>Completed</h3>
      <h4>OpenHID Lab, HPDRC, among others</h4>
      <h4>Ortega, Rishe, Emmanuel Norde, Bryan Rodriguez, Fernando Garcia, Juan Araguren, Galvan, Thomas, Balcazar</h4>
      <p>The Smart Learning Desk is currently being developed to integrate vision and touch targeted for the advancement of K-12 and college education.</p><a style="padding:16px" href="https://sites.google.com/site/vrkelvar/vr2016">webpage</a><a style="padding:16px" href="https://docs.google.com/viewer?a=v&amp;amp;pid=sites&amp;amp;srcid=ZGVmYXVsdGRvbWFpbnx2cmtlbHZhcnxneDoxZWUyMTc0YjgwNDZkYjQ4">google docs</a>
    </article>
  </section>
  <section style="background-color: rgba(235,235,235, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>TAMGeF: Touch, midAir, and Motion Gesture Framework</h2>
      <h3>In Progress</h3>
      <h4>OpenHID Lab and HPDRC</h4>
      <h4> Ortega, Rishe, Thomas, Balcazar, Galvan</h4>
      <p>TAMGeF is a modern, parallel, template-based C++ API for multi-touch (and pen), mid-air (vision-based devices), and motion (e.g., gyroscope) devices with the purpose of recognizing multiple gestures.</p><a style="padding:16px" href="https://www.youtube.com/watch?v=PbSF8dhGgpA">video (youtube)</a><a style="padding:16px" href="https://dl.acm.org/citation.cfm?id=2794355">ACM</a><a style="padding:16px" href="http://openhid.com/assets/papers/tamgef-_touch-midair-motion_framework_for_spatial_input.pdf">pdf</a>
    </article>
  </section>
  <section style="background-color: rgba(255,255,255, 0.9);"><img width="300" height="200" alt="/assets/brand/placeholder.jpg" src="./OpenHID Lab3_files/placeholder.jpg">
    <article style="padding: 16px">
      <h2>Spider Sensor</h2>
      <h3>Completed</h3>
      <h4>OpenHID Lab, HPDRC, Calella, mong others</h4>
      <h4>Ortega, Barreto, Rishe</h4>
      <p>The project covers the design of new hardware for motion sensing and the development of gesture algorithms for this type of sensor. </p><a style="padding:16px" href="http://ieeexplore.ieee.org/abstract/document/7808524/">IEEE Xplore</a><a style="padding:16px" href="http://openhid.com/assets/papers/handmagic-_towards_user_interaction_with_inertial_measuring_units.pdf">pdf</a>
    </article>
  </section>
  <footer class="footer"><a href="http://cis.fiu.edu/"><img src="./OpenHID Lab3_files/fiu-cis-logo.svg" alt="Logo image" style="width: 240px"></a>
    <hr>
    <p>The OpenHID lab is a member of the FIU College of Computing Sciences  <a href="http://hpdrc.fiu.edu/">High Performance Database Research Center.</a></p>
  </footer>
</body></html>